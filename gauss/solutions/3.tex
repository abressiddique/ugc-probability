\begin{lemma}
    \label{gauss/3/xy}
Let 
\begin{align}
    \vec{x}=\myvec{X_1\\
             X_2\\
             X_3\\
             X_4\\
             X_5}
, 
             \vec{y}=\myvec{Y_1\\
             Y_2\\
             Y_3\\
             Y_4\\
             Y_5}, 
             \sim \gauss{\vec{0}}{\vec{I}}
             \\
% \end{align}
% and 
% \begin{align}
    \vec{u}&=\myvec{1\\ 1\\ 1\\ 1\\ 1}, 
    \vec{v}=\myvec{1\\ 1\\ 1\\ 1\\ 0}.
\end{align} 
%
Then 
\begin{align}
    \overline{X}&=\frac{1}{5}\vec{u}^{\top}\vec{x}
    \\
    T &= \norm{\vec{v}^{\top}\vec{y}}^2
    \label{gauss/3/T}
\end{align}
where
\begin{align}
\vec{y} &= \vec{P}\vec{x}, 
\\
\vec{M} &= \vec{I}- \frac{1}{5}\vec{1}
\\
&= \vec{P}^{\top}\vec{D}\vec{P}, 
\\
    \vec{D} &=\myvec{1&0&0&0&0\\
                   0&1&0&0&0\\
                   0&0&1&0&0\\
                   0&0&0&1&0\\
                   0&0&0&0&0}
\end{align}
% \begin{align}
% %     \vec{M}&=\myvec{\frac{4}{5}&-1/5&-1/5&-1/5&-1/5\\
% %                    -1/5&\frac{4}{5}&-1/5&-1/5&-1/5\\
% %                    -1/5&-1/5&\frac{4}{5}&-1/5&-1/5\\
% %                    -1/5&-1/5&-1/5&\frac{4}{5}&-1/5\\
% %                    -1/5&-1/5&-1/5&-1/5&\frac{4}{5}}
% \vec{M} = \vec{I}- \frac{1}{5}\vec{1}
%  \end{align}
  and $\vec{1}$ is the all ones matrix.
\end{lemma}
%
\begin{proof}
From  \eqref{gauss/3/mean} and  \eqref{gauss/3/var}, it is easy to verify that 
\begin{align}
       T&=\vec{x}^{\top}\vec{M}\vec{x},
    \vec{M}^2=\vec{M}
    \\
    \implies T&=\vec{x}^{\top}\vec{P}\vec{D}\vec{P}^{\top}\vec{x}\\
    &=\vec{y}^{\top}\vec{D}\vec{y}
\end{align}
yielding     \eqref{gauss/3/T}.  We have used spectral decomposition above.
%
\end{proof}
\begin{lemma}    
    \label{gauss/3/orth}
    $\vec{y}=\vec{P}\vec{x} \sim \gauss{\vec{0}}{\vec{I}}$ if $\vec{P}^{\top}\vec{P} = \vec{I}$.
\end{lemma}
\begin{proof}
    The  moment generating function 
    \begin{align}
        M_{\vec{x}}\brak{\vec{t}}=exp\brak{\vec{t}^{\top}\vec{\mu}+\frac{1}{2}\vec{t}^{\top}\vec{V}\vec{t}}
    \end{align}
    $\because \vec{\mu}=\vec{0}$ and $\vec{V}=\vec{I}$,
    \begin{align}
         M_{\vec{x}}\brak{\vec{t}}=\exp\brak{\frac{1}{2}\vec{t}^{\top}\vec{t}}\label{gauss/3/2.11}
    \end{align}
    Therefore the joint moment generating function of $\vec{y}$ is
    \begin{align}
        M_{\vec{y}}\brak{\vec{t}}&=M_{\vec{x}}\brak{\vec{P}\vec{t}}\\
        &=exp\brak{\frac{1}{2}\vec{t}^{\top}\vec{P}^{\top}\vec{P}\vec{t}}
        \\
        &= M_{\vec{x}}\brak{\vec{t}}
    \end{align}
%    on comparing with $\eqref{gauss/3/2.11}$ we can say $\vec{y}$ has multivariate normal distribution. 
    \end{proof}
    \begin{corollary}
        \label{gauss/3/xbar}
        $\overline{X} \sim \gauss{0}{\frac{1}{5}}$
    \end{corollary}

    \begin{definition}
        \begin{enumerate}
        \item {\em Random Variable:} A random variable X is a real-valued function defined on the "sample space" $\Omega$ (the set of outcomes being studied via probability).
        \item {\em Borel Set:} A random variable X is studied by means of the probabilities that its value lies within various intervals of real numbers (or, more generally, sets constructed in simple ways out of intervals: these are the Borel measurable sets of real numbers).         
        \item {sigma-algebra: }  Corresponding to any Borel measurable set I is the event $X^*(I)$ consisting of all outcomes $\omega$ for which $X(\omega)$ lies in I.
        The sigma-algebra generated by X is determined by the collection of all such events.
        \item {\em Independent random variables: } The naive definition says two random variables X and Y are independent "when their probabilities multiply." That is, when I is one Borel measurable set and J is another, then 
        \begin{multline}
            \pr{X(\omega)\in I , Y(\omega)\in J}\\=\pr{X(\omega)\in I}\pr{Y(\omega)\in J}.
        \end{multline}
        But in the language of events (and sigma algebras) that's the same as
        \begin{multline}
            \pr{\omega \in X^*(I) , \omega \in Y^*(J)}\\=\pr{\omega \in X^*(I)}\pr{\omega \in Y^*J)}.
        \end{multline}
        \item {\em Function of a random variable: }
        \begin{align}
            (f\circ X)(\omega)&=f(X(\omega))
            \\
            (f\circ X)^*(I)&=X^*(f^*(I))
            \label{eq:gauss/3/omega}
        \end{align}
        \end{enumerate}
    
    \end{definition}
    
\begin{lemma}
    Functions of independent random variables are themselves independent.
    \end{lemma}
    \begin{proof}
     Consider now two functions $f,g:\mathbb{R}\rightarrow \mathbb{R}$ and suppose that $f\circ X$ and $g\circ Y$ are random variables. 
    In other words, every event generated by $f\circ X$ (which is on the left) in         \eqref{eq:gauss/3/omega} is automatically an event generated by X (as exhibited by the form of the right hand side). Therefore         \eqref{eq:gauss/3/omega} automatically holds for $f\circ X$ and $g\circ Y$.
    This covers the case of vector-valued random variables as well.
    \end{proof}
    \begin{corollary}
        Let $\vec{y}$ and $\vec{z}$ be two independent normal random vectors. Then $\vec{y}$ and $\vec{\norm{z}}$ are also independent.
    \end{corollary}

    \begin{lemma}
        \label{gauss/3/t2.3}    
        $\vec{A}\vec{x}, \vec{B}\vec{x}$ are  independent  if and only if $\vec{A}\vec{B}^{\top}=0$
        \end{lemma}
        \begin{proof}
        The given vectors are independent $\iff$ 
        \begin{multline}
            \mean{\brak{\vec{A}\vec{x}-\mean{\vec{A}\vec{x}}}\brak{\vec{B}\vec{x}-\mean{\vec{B}\vec{x}}}^{\top}} = 0\\
             \implies \vec{A}\mean{\brak{\vec{x}-\mean{\vec{x}}}\brak{\vec{x}-\mean{\vec{x}}}^{\top}}\vec{B}^{\top} = 0\\
             \implies \vec{A}\var{\vec{x}}\vec{B}^{\top} = 0\\
             \text{or, } \vec{A}\vec{B}^{\top} = 0, \quad \because \var{\vec{x}} = \vec{I}
        \end{multline}        
        \end{proof}
\begin{theorem}    
    $\vec{u}^{\top}\vec{x}$ and $\vec{v}^{\top}\vec{y}$ are independent.
\end{theorem}
\begin{proof}
    From Lemma     \ref{gauss/3/xy}, 
    \begin{align}
        \vec{y} = \vec{P}\vec{x}. 
    \end{align}        
The given statement can be proved  using Lemma         \ref{gauss/3/t2.3} and noting that      
    \begin{align}
        \vec{u}^{\top}\vec{P}^{\top} \vec{v}=0, 
    \end{align}            
\end{proof}
\begin{corollary}    
    $\overline{X} and T$ are independent.
\end{corollary}
    % \begin{conjecture}
    %     \label{l2.1/gauss/3/}
    %     For any vectors $\vec{u}, \vec{v}$, 
    %     \begin{align}
    %        \brak{\vec{u}^{\top}\vec{x}}\brak{\vec{x}^{\top}\vec{v}}=\vec{u}^{\top}\brak{\vec{x}\vec{x}^{\top}}\vec{v}
    %     \end{align}
    % \end{conjecture}
\begin{definition}
    \label{gauss/3/chisq}
    {\em chi-square distribution: } $\norm{\vec{x}}^2$ is said to be chi-square distributed.  If the length of $\vec{x}$ is $k$,
 The mean and variance are given by
 \begin{align}
   \mean{Y}&=k\\
   \var{Y}&=2k
 \end{align}
\end{definition}
From       Corollary  \ref{gauss/3/xbar} and      Definition \ref{gauss/3/chisq},
\begin{align}
    \mean{\overline{X}^2} &= \frac{1}{5}, 
    \\
    \mean{T^2} &=  \var{T}+\brak{\mean{T}}^2\\
    &=24
    \\
    \implies  \mean{T^2\overline{X}^2}=4.8
\end{align}