We using
\begin{enumerate}[label=\alph*)]
\item 
\begin{enumerate}[label=(\arabic*)]
\item {\em Convergence in probability : }Let $X_{1}, X_{2}, \ldots$ be an infinite sequence of random variables, and let $Y$ be another random variable. Then the sequence $\left\{X_{n}\right\}$ converges in probability to $Y$, if
\begin{align}
\forall \epsilon>0, \lim _{n \rightarrow \infty} \pr{\left|X_{n}-Y\right| \geq \epsilon}=0,
\end{align}
and we write 
\begin{align}
X_{n} \stackrel{P}{\rightarrow} Y.
\end{align}
\item {\em Convergence in almost surely : }Let $X_{1}, X_{2}, \ldots$ be an infinite sequence of random variables. We shall say that the sequence $\left\{X_{i}\right\}$ converges with probability 1 (or converges almost surely (a.s.)) to a random variable $Y$, if 
\begin{align}
\pr{\lim _{n \rightarrow \infty} X_{n}=Y}=1
\end{align}
and we write
\begin{align}
X_{n} \stackrel{a . s .}{\rightarrow} Y
\end{align}
\item {\em Strong law of large number(SLLN) : }Let $X_{1}, X_{2}, \ldots$ be an infinite sequence of random variables, If $\mathbf{E}\left[\left|X_{1}\right|\right]<\infty$. Then, as $n \rightarrow \infty$ , we have 
\begin{align}
\dfrac{S_{n}}{n} \stackrel{a.s.}{\rightarrow} \mathbf{E}\left[X_{1}\right]\implies \dfrac{S_{n}}{n} \stackrel{P}{\rightarrow} \mathbf{E}\left[X_{1}\right],
\label{june/2017/50eq} \\
\text{where} ,\,S_n = X_1 + \cdots + X_n
\end{align}  
\end{enumerate}
using SLLN, $(\mathrm{B})$ are incorrect option.
\item {\em Relation between in probability and almost surely : }Let $Z, Z_{1}, Z_{2}, \ldots$ be random variables. Suppose $Z_{n} \rightarrow Z$ with probability 1. Then ,we say 
\begin{align}
 Z_n \stackrel{a.s.}{\rightarrow} Z \implies Z_n \stackrel{P}{\rightarrow} Z.
\end{align}
\eqref{june/2017/50eq}, also in probability also hold this equation. Hence $(\mathrm{A})$ is incorrect option.  
\item 
{\em Central Limit Theorem : }Let $X_{1}, X_{2}, \ldots$ be i.i.d. with finite mean $\mu$ and finite variance $\sigma^{2}$. Let $Z \sim N(0,1) .$ Set $S_{n}=X_{1}+\cdots+X_{n}$, and
\begin{align}
Z_{n}=\frac{S_{n}-n \mu}{\sqrt{n \sigma^{2}}}
\end{align}
Then as $n \rightarrow \infty$, the sequence $\left\{Z_{n}\right\}$ converges in distribution to the $Z$, i.e., $Z_{n} \stackrel{D}{\rightarrow} Z$.\\
Consider,
\begin{align}
Y=\dfrac{X_{1}+ X_{2}+ \cdots + X_n}{\sqrt{n}}
\end{align}
So,
\begin{align}
E(Y)= E\left(\dfrac{X_{1}+ X_{2}+ \cdots+X_n}{\sqrt{n}}\right)= 0\\
V(Y)= V\left(\dfrac{X_{1}+ X_{2}+ \cdots+X_n}{\sqrt{n}}\right)= \frac{1}{n}2n=2
\end{align}
\begin{align}
Y \sim N[0,2]
\end{align}
we know that,
\begin{align}
f(x)=f(-x)\implies \text{Symmetry about Zero},
\end{align}
So,
\begin{align}
\pr{Y<0}=\frac{1}{2}
\end{align}
\begin{align}
\pr{\dfrac{1}{\sqrt{n}}\left(X_{1}+\cdots+X_{n}\right)<0}=\frac{1}{2}
\end{align}
Hence$,(\mathrm{C})$ is incorrect option.
\item {\em Characteristic function : }For a scalar random variable $X$ the characteristic function is defined as the expected value of $\mathrm{e}^{i t \times}$, where $i$ is the imaginary unit, and $t \in \mathbf{R}$ is the argument of the characteristic function:
\begin{align}
\left\{\begin{array}{l}
\varphi_{X}: \mathbb{R} \rightarrow \mathbb{C} \\
\varphi_{X}(t)=\mathrm{E}\left[e^{i t X}\right]=\int_{\mathbb{R}} e^{i t x} d F_{X}(x)\\=\int_{\mathbb{R}} e^{i t x} f_{X}(x) d x=\int_{0}^{1} e^{i t Q_{X}(p)} d p
\end{array}\right.
\end{align}
Here $F_X$ is the cumulative distribution function of $X$,Consider, $\phi_{x}(t)$ is characteristic function of $X_{i}, i=1, \ldots, n.$
\begin{align}
f(x)=f(-x)\implies \phi_{x}(t)=\phi_{-x}(t)
\end{align}
Therefore,
\begin{align}
\phi_{\sum_{i=1}^{n}X_i}(t) = \phi_{X_{1}+\ldots +X_{n}}(t) &=\phi_{X_{1}}(t)\cdots\phi_{X_{n}}(t)\\
&=\left[\phi_{x}(t)\right]^{n}
\end{align}
similarly,
\begin{align}
\phi_{\sum_{i=1}^{n}(-1)^{i}X_i}(t) &= \phi_{-X_{1}}+\phi_{X_{2}}+\ldots +\phi_{(-1)^{n}X_{n}}(t)\\
&=\phi_{-X_{1}}(t) \cdot \phi_{X_{2}}(t)\cdots\phi_{(-1)^{n}X_{n}}(t)\\
&=\left[\phi_{x}(t)\right]^{n}\\
\phi_{\sum_{i=1}^{n}X_i}(t) &= \phi_{\sum_{i=1}^{n}(-1)^{i}X_i}(t)
\end{align}
$\therefore \sum_{i=1}^{n} X_{i}$ has same distribution as $\sum_{i=1}^{n}(-1)^{i} X_{i}.$\\
Hence, only $(\mathrm{D})$ is correct option.
\end{enumerate}